{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba5270-eedd-4b06-878a-d35448547f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#V3 - refmaking fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d30c7-aebb-4aa8-a7f7-bef2b2c78f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63424e63-a1df-4ac4-bb32-319e7cdb02f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "\n",
    "# Set options to display a specific number of columns and control column width\n",
    "pd.set_option('display.max_columns', 20)  # Set the maximum number of columns to display\n",
    "pd.set_option('display.max_colwidth', 100)  # Set the maximum column width for text data\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7858da-d40c-49f0-be08-9060a91237d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define your cell types and paths\n",
    "cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"]  # etc.\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"  # or some default value\n",
    "\n",
    "# Read metadata\n",
    "metadat = pd.read_csv(metadat_path)\n",
    "unique_projects = metadat['Project/Dataset'].unique()\n",
    "#unique_projects = [\"h_KPMP\", \"cal_CKD\"]\n",
    "\n",
    "# Initialize a DataFrame to store the average normalized percentage for each feature\n",
    "average_normalized_percentage_df = pd.DataFrame()\n",
    "\n",
    "for project in unique_projects:\n",
    "    unique_samples = metadat[(metadat['Disease_level2'] != \"Control\") & (metadat['Project/Dataset'] == project)]['Sample'].unique()\n",
    "\n",
    "    # Initialize combined dataframes for R2 and p-values for this project\n",
    "    combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "    combined_pval = pd.DataFrame(index=unique_samples)\n",
    "    sample_counts_per_cell_type = {}\n",
    "\n",
    "    for cell_type in cell_types:\n",
    "        r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "        pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "        \n",
    "        r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "        pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "\n",
    "        # Modify column names\n",
    "        r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "        pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "        \n",
    "        # Filter r2_df to only include rows where the index is in unique_samples\n",
    "        r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "\n",
    "        # Merge data\n",
    "        combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "        combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "        # Count samples per cell type\n",
    "        sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "\n",
    "    # Handle NA values in p-values\n",
    "    combined_pval.fillna(1, inplace=True)\n",
    "\n",
    "    # Initialize a MinMaxScaler and scale the combined_r2 data\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    min_max_scaled_r2_values = min_max_scaler.fit_transform(combined_r2.values)\n",
    "    combined_r2 = pd.DataFrame(min_max_scaled_r2_values, index=combined_r2.index, columns=combined_r2.columns)\n",
    "\n",
    "    # Set p-value threshold and identify significant gene sets\n",
    "    p_value_threshold = 0.05\n",
    "    significant_matrix = combined_pval < p_value_threshold\n",
    "    significant_counts = significant_matrix.sum()\n",
    "\n",
    "    # Create DataFrame for counts and cell types\n",
    "    significant_counts_df = pd.DataFrame({'GeneSet': significant_counts.index, 'Count': significant_counts.values})\n",
    "    significant_counts_df['CellType'] = significant_counts_df['GeneSet'].apply(extract_cell_type)\n",
    "\n",
    "    # Add a column for the normalized percentage for the current project\n",
    "    project_column = f\"NormalizedPercentage_{project}\"\n",
    "    significant_counts_df[project_column] = significant_counts_df.apply(\n",
    "        lambda row: (row['Count'] / sample_counts_per_cell_type.get(row['CellType'], 1)) * 100, axis=1\n",
    "    )\n",
    "\n",
    "    if average_normalized_percentage_df.empty:\n",
    "        # For the first project, initialize the DataFrame\n",
    "        average_normalized_percentage_df = significant_counts_df[['GeneSet', project_column]]\n",
    "    else:\n",
    "        # For subsequent projects, merge their data into the DataFrame\n",
    "        average_normalized_percentage_df = average_normalized_percentage_df.merge(\n",
    "            significant_counts_df[['GeneSet', project_column]],\n",
    "            on='GeneSet',\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "# After all projects are processed, calculate the average\n",
    "average_column = 'AverageNormalizedPercentage'\n",
    "average_normalized_percentage_df[average_column] = average_normalized_percentage_df.filter(like='NormalizedPercentage_').mean(axis=1)\n",
    "\n",
    "# Sort the features based on the average normalized percentage\n",
    "sorted_average_df = average_normalized_percentage_df.sort_values(by=average_column, ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_average_df.head())  # Modify this to display as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b590b7d-7ed1-477e-af5b-ad24d1d9bc9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_average_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab50d06-0d11-4754-b824-22b0a02bec51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replace with your actual file paths and cell types\n",
    "cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"] # etc.\n",
    "# Paths as specified in your first script\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"  # or some default value\n",
    "\n",
    "# Read metadata\n",
    "metadat = pd.read_csv(metadat_path)\n",
    "unique_samples = metadat[metadat['Disease_level2'] != \"Control\"]['Sample'].unique()\n",
    "#unique_samples = metadat[(metadat['Disease_level2'] != \"Control\") & (metadat['Project/Dataset'] == \"cal_CKD\")]['Sample'].unique()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    \n",
    "    # Modify column names\n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    # Merge data\n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    # Count samples per cell type\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "\n",
    "# Handle NA values in p-values\n",
    "combined_pval.fillna(1, inplace=True)\n",
    "\n",
    "print(combined_r2)\n",
    "\n",
    "# Initialize a MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the combined_r2 data\n",
    "# Note: The fit_transform method expects a 2D array, so we use .values to convert the DataFrame\n",
    "min_max_scaled_r2_values = min_max_scaler.fit_transform(combined_r2.values)\n",
    "\n",
    "# Create a new DataFrame from the min-max scaled data, preserving the index and column names\n",
    "\n",
    "combined_r2 = pd.DataFrame(min_max_scaled_r2_values, index=combined_r2.index, columns=combined_r2.columns)\n",
    "\n",
    "# Set p-value threshold\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "# Identify significant gene sets\n",
    "significant_matrix = combined_pval < p_value_threshold\n",
    "\n",
    "# Count significant occurrences\n",
    "significant_counts = significant_matrix.sum()\n",
    "\n",
    "# Create DataFrame for counts and cell types\n",
    "significant_counts_df = pd.DataFrame({'GeneSet': significant_counts.index, 'Count': significant_counts.values})\n",
    "\n",
    "# Apply the function to extract the full cell type name\n",
    "significant_counts_df['CellType'] = significant_counts_df['GeneSet'].apply(extract_cell_type)\n",
    "\n",
    "# Normalize by sample number per cell type\n",
    "significant_counts_df['NormalizedPercentage'] = significant_counts_df.apply(\n",
    "    lambda row: (row['Count'] / sample_counts_per_cell_type.get(row['CellType'], 1)) * 100, axis=1\n",
    ")\n",
    "\n",
    "# Display final DataFrame\n",
    "print(significant_counts_df.head())  # You can modify this to display as needed\n",
    "\n",
    "sorted_df = significant_counts_df.sort_values(by='NormalizedPercentage', ascending=False)\n",
    "display(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5391e-2a9e-4c01-a862-49e8dcc95f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sample_of_interest = 'KRAD60'\n",
    "\n",
    "#max_value = 300\n",
    "\n",
    "ct_plot1 = \"Podo\"\n",
    "\n",
    "ct_plot2 = \"PEC\"\n",
    "\n",
    "ct_plot3 = \"PT\"\n",
    "\n",
    "\n",
    "# Replace with your actual file paths and cell types\n",
    "cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"] # etc.\n",
    "# Paths as specified in your first script\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"  # or some default value\n",
    "\n",
    "# Read metadata\n",
    "metadat = pd.read_csv(metadat_path)\n",
    "unique_samples = metadat[metadat['Disease_level2'] != \"Control\"]['Sample'].unique()\n",
    "#unique_samples = metadat[(metadat['Disease_level2'] != \"Control\") & (metadat['Project/Dataset'] == \"cal_CKD\")]['Sample'].unique()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    \n",
    "    # Modify column names\n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    # Merge data\n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    # Count samples per cell type\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "\n",
    "# Handle NA values in p-values\n",
    "combined_pval.fillna(1, inplace=True)\n",
    "\n",
    "print(combined_r2)\n",
    "\n",
    "# Initialize a MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the combined_r2 data\n",
    "# Note: The fit_transform method expects a 2D array, so we use .values to convert the DataFrame\n",
    "min_max_scaled_r2_values = min_max_scaler.fit_transform(combined_r2.values)\n",
    "\n",
    "# Create a new DataFrame from the min-max scaled data, preserving the index and column names\n",
    "\n",
    "combined_r2 = pd.DataFrame(min_max_scaled_r2_values, index=combined_r2.index, columns=combined_r2.columns)\n",
    "\n",
    "# Set p-value threshold\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "# Identify significant gene sets\n",
    "significant_matrix = combined_pval < p_value_threshold\n",
    "\n",
    "# Count significant occurrences\n",
    "significant_counts = significant_matrix.sum()\n",
    "\n",
    "# Create DataFrame for counts and cell types\n",
    "significant_counts_df = pd.DataFrame({'GeneSet': significant_counts.index, 'Count': significant_counts.values})\n",
    "\n",
    "# Apply the function to extract the full cell type name\n",
    "significant_counts_df['CellType'] = significant_counts_df['GeneSet'].apply(extract_cell_type)\n",
    "\n",
    "# Normalize by sample number per cell type\n",
    "significant_counts_df['NormalizedPercentage'] = significant_counts_df.apply(\n",
    "    lambda row: (row['Count'] / sample_counts_per_cell_type.get(row['CellType'], 1)) * 100, axis=1\n",
    ")\n",
    "\n",
    "# Display final DataFrame\n",
    "print(significant_counts_df.head())  # You can modify this to display as needed\n",
    "\n",
    "sorted_df = significant_counts_df.sort_values(by='NormalizedPercentage', ascending=False)\n",
    "display(sorted_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "    # Split the label into words\n",
    "    words = label.split()\n",
    "\n",
    "    # Function to remove suffix\n",
    "    def remove_suffix(word):\n",
    "        return re.sub(r'\\(GO:\\d{7}\\)$', '', word)\n",
    "\n",
    "    # Start with the first word (with suffix removed)\n",
    "    first_word = remove_suffix(words[0])\n",
    "    split_label = first_word\n",
    "    current_length = len(first_word)\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        word = remove_suffix(word)\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "\n",
    "# Provided cell types and colors\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#000004\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Function to extract cell type from feature name\n",
    "def extract_cell_type(feature_name):\n",
    "    for cell_type in cell_colors.keys():\n",
    "        if feature_name.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Sample data - replace with your actual data\n",
    "\n",
    "top_20_features = combined_pval.loc[sample_of_interest].nsmallest(25)\n",
    "neg_log_pvals = -np.log10(top_20_features)\n",
    "r2_values = combined_r2.loc[sample_of_interest][top_20_features.index]\n",
    "\n",
    "# Create a reversed red colormap for R2 values\n",
    "cmap = plt.cm.Reds_r  # '_r' suffix to reverse the colormap\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)  # Normalization fixed from 0 to 1\n",
    "\n",
    "# Assuming 'significant_counts_df' is your DataFrame and it has a 'GeneSet' and 'NormalizedPercentage' column\n",
    "scale_factor = 4\n",
    "base_size = 100\n",
    "#base_size = 20\n",
    "\n",
    "# Map features to their normalized percentage\n",
    "feature_to_percentage = dict(zip(significant_counts_df['GeneSet'], significant_counts_df['NormalizedPercentage']))\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(top_20_features.index, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "ax.set_title(f'Top Features for Sample {sample_of_interest}', fontsize=14)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left')\n",
    "ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define your desired order of cell types\n",
    "desired_order = [\n",
    "     \n",
    "\"PT\", \n",
    "\"TAL\", \n",
    "\"DCT_CNT_CD\", \n",
    "\"IC\",    \n",
    "\"EC\",\n",
    "\"Stromal\",      \n",
    "\"Immune\",   \n",
    "\"DTL_ATL\",  \n",
    "\"PEC\",           \n",
    "\"Podo\",    \n",
    "\n",
    "    \n",
    "] \n",
    "\n",
    "sample_features = combined_pval.loc[sample_of_interest]\n",
    "\n",
    "top_20_features = sample_features[sample_features < p_value_threshold]\n",
    "\n",
    "# Assume 'combined_pval' is a DataFrame you have that contains the p-values\n",
    "\n",
    "# Select the top 50 gene sets from the top features\n",
    "top_gene_sets = top_20_features.index\n",
    "\n",
    "# Group the top gene sets by cell type\n",
    "grouped_data = pd.Series(top_gene_sets).apply(extract_cell_type).value_counts()\n",
    "\n",
    "categories = list(grouped_data.index)\n",
    "\n",
    "# Initialize ordered values with zero for all categories\n",
    "ordered_values = [grouped_data.get(ct, 0) for ct in desired_order]\n",
    "\n",
    "# Since we need to repeat the first value to close the circular graph\n",
    "ordered_values += ordered_values[:1]\n",
    "\n",
    "# Calculate the angle of each axis in the plot\n",
    "N = len(desired_order)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize the spider plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], desired_order)\n",
    "\n",
    "# Draw ylabels and set plot limits\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(color=\"grey\", size=5)\n",
    "\n",
    "\n",
    "#plt.ylim(0, max_value)\n",
    "\n",
    "\n",
    "# Neutral color for shading\n",
    "shade_color = 'lightgrey'\n",
    "\n",
    "# Fill the entire area under the radar chart with a neutral color\n",
    "ax.fill(angles, ordered_values, shade_color, alpha=0.9)\n",
    "\n",
    "# Draw thin lines connecting the points\n",
    "ax.plot(angles, ordered_values, color='grey', linewidth=1, linestyle='-', alpha=0.8)\n",
    "\n",
    "# Plot each line segment in its respective cell type color\n",
    "for idx in range(N):\n",
    "    color = cell_colors.get(desired_order[idx], \"grey\")\n",
    "    ax.plot([angles[idx], 0], [ordered_values[idx], 0], color=color, linewidth=2)\n",
    "\n",
    "# Change the color of tick labels to red if the cell type is missing\n",
    "for idx, label in enumerate(ax.get_xticklabels()):\n",
    "    if desired_order[idx] not in categories:\n",
    "        label.set_color('red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Cell Type Distribution in Top Gene Sets for Sample ' + sample_of_interest, size=11, y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot1\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot2\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot3\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc9d68-e9b0-4b1d-8d7c-861ea6760776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d0d95-ad2d-49f1-9aff-eeca775cf9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d239f7-acc8-4a72-bb85-2bc15517c57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'sorted_df' is your DataFrame\n",
    "# Select the top 100 features\n",
    "repetitive_features = sorted_df[sorted_df[\"NormalizedPercentage\"] >= 25]\n",
    "\n",
    "# Remove the CellType prefix from the GeneSet column\n",
    "repetitive_features['GeneSetOnly'] = repetitive_features.apply(\n",
    "    lambda row: row['GeneSet'].replace(row['CellType'] + '_', ''), axis=1\n",
    ")\n",
    "\n",
    "repetitive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce001a08-0c29-4fba-a580-409c84d41a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(repetitive_features[\"GeneSetOnly\"].unique())\n",
    "\n",
    "len(repetitive_features[\"GeneSetOnly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252b50d-f10f-4795-84f8-0a2d6572bed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repetitive_features.to_csv(\"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/Frequent_features_disease_R1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c74341-e7bb-44e3-b88c-0d78966ea348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'repetitive_features' is your DataFrame\n",
    "# Count the frequency of each gene set across different cell types\n",
    "gene_set_frequencies = repetitive_features.groupby('GeneSetOnly')['CellType'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "gene_set_frequencies.columns = ['GeneSet', 'NumberOfCellTypes']\n",
    "\n",
    "# Now, gene_set_frequencies DataFrame contains each gene set and the number of cell types it's observed in\n",
    "# Sort the DataFrame in descending order based on the number of cell types\n",
    "gene_set_frequencies_sorted = gene_set_frequencies.sort_values(by='NumberOfCellTypes', ascending=False)\n",
    "\n",
    "# Now, gene_set_frequencies_sorted is sorted with the most frequently observed gene sets at the top\n",
    "gene_set_frequencies_sorted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c2374-8f9b-4e43-9001-013b0c2be623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "    # Split the label into words\n",
    "    words = label.split()\n",
    "\n",
    "    # Function to remove suffix\n",
    "    def remove_suffix(word):\n",
    "        return re.sub(r'\\(GO:\\d{7}\\)$', '', word)\n",
    "\n",
    "    # Start with the first word (with suffix removed)\n",
    "    first_word = remove_suffix(words[0])\n",
    "    split_label = first_word\n",
    "    current_length = len(first_word)\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        word = remove_suffix(word)\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "# Assuming 'repetitive_features' is your DataFrame\n",
    "# Identify the top common feature for each cell type\n",
    "top_features_per_celltype = repetitive_features.loc[repetitive_features.groupby('CellType')['NormalizedPercentage'].idxmax()]\n",
    "\n",
    "# Sort the DataFrame based on NormalizedPercentage in ascending order for horizontal plot\n",
    "top_features_per_celltype_sorted = top_features_per_celltype.sort_values(by='NormalizedPercentage', ascending=True)\n",
    "\n",
    "# Your specific color map for cell types\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#555555\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Plotting the horizontal bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = plt.barh(top_features_per_celltype_sorted['CellType'], top_features_per_celltype_sorted['NormalizedPercentage'],\n",
    "                   color=[cell_colors[ct] for ct in top_features_per_celltype_sorted['CellType']])\n",
    "\n",
    "# Setting the y-axis labels using the auto_split_label function\n",
    "plt.yticks(top_features_per_celltype_sorted['CellType'], \n",
    "           [auto_split_label(gs) for gs in top_features_per_celltype_sorted['GeneSetOnly']], fontsize = 18)\n",
    "\n",
    "plt.xlabel('Normalized Percentage')\n",
    "plt.title('Top Common Features per Cell Type (Sorted by Normalized Percentage)')\n",
    "plt.tight_layout()  # Adjusts the plot to ensure everything fits without overlapping\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9167adb-946a-4dec-974f-2620082eeaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Function to split long labels\n",
    "def auto_split_label(label, max_length=50):\n",
    "    words = label.split()\n",
    "    split_label = words[0]\n",
    "    current_length = len(words[0])\n",
    "\n",
    "    for word in words[1:]:\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "# Assuming 'sorted_df' is your DataFrame with columns ['CellType', 'GeneSet', 'NormalizedPercentage']\n",
    "\n",
    "# Create a new column 'GeneSetOnly' by removing the cell type prefix from 'GeneSet'\n",
    "sorted_df['GeneSetOnly'] = sorted_df.apply(lambda row: row['GeneSet'].replace(row['CellType'] + '_', ''), axis=1)\n",
    "\n",
    "# Filter for top 100 features\n",
    "top_100_features = sorted_df[sorted_df[\"NormalizedPercentage\"] >= 25]\n",
    "\n",
    "# Identify cell-type specific gene sets\n",
    "unique_gene_sets = top_100_features.groupby('GeneSetOnly').filter(lambda x: len(x['CellType'].unique()) == 1)\n",
    "\n",
    "# Identify the top common feature for each cell type\n",
    "top_features_per_celltype = unique_gene_sets.loc[unique_gene_sets.groupby('CellType')['NormalizedPercentage'].idxmax()]\n",
    "\n",
    "# Sort the DataFrame based on NormalizedPercentage in ascending order for horizontal plot\n",
    "top_features_per_celltype_sorted = top_features_per_celltype.sort_values(by='NormalizedPercentage', ascending=True)\n",
    "\n",
    "# Your specific color map for cell types\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#555555\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Plotting the horizontal bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_features_per_celltype_sorted['CellType'], top_features_per_celltype_sorted['NormalizedPercentage'],\n",
    "         color=[cell_colors[ct] for ct in top_features_per_celltype_sorted['CellType']])\n",
    "\n",
    "# Setting the y-axis labels using the auto_split_label function\n",
    "plt.yticks(top_features_per_celltype_sorted['CellType'], \n",
    "           [auto_split_label(gs) for gs in top_features_per_celltype_sorted['GeneSetOnly']], fontsize=18)\n",
    "\n",
    "plt.xlabel('Normalized Percentage')\n",
    "plt.title('Top Cell-Type Specific Features per Cell Type (Sorted by Normalized Percentage)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ade440-1ad7-4c1f-8994-bf20ed75231b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#555555\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Assuming 'sorted_conserved_features' is already available from previous steps\n",
    "\n",
    "# Select the top 100 features\n",
    "top_100_features = sorted_df[sorted_df[\"NormalizedPercentage\"] >= 25]\n",
    "\n",
    "# Count the frequency of each CellType in the top 100 features\n",
    "cell_type_counts = top_100_features['CellType'].value_counts()\n",
    "\n",
    "# Extract the colors corresponding to the cell types\n",
    "pie_colors = [cell_colors[cell_type] for cell_type in cell_type_counts.index if cell_type in cell_colors]\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(5, 5))  # Adjust the size as needed\n",
    "cell_type_counts.plot(kind='pie', colors=pie_colors, autopct='')\n",
    "plt.title('25% of patients cut-off')\n",
    "plt.ylabel(len(top_100_features))  # Hide the y-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830da87-898d-49ad-9bb3-485d0e8942cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3937d0-9ad1-42d5-a29c-ebd092f21951",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_threshold = 0.05\n",
    "\n",
    "sample_of_interest = \"KRAD70\"\n",
    "\n",
    "#max_value = 300\n",
    "\n",
    "ct_plot1 = \"PT\"\n",
    "\n",
    "#specify how many nan we tolerate (critical if applying gene filtering during spectra analysis)\n",
    "nan_threshold = 1000\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define cell types and file paths\n",
    "cell_types = [\"PT\", \"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"IC\", \"Immune\", \"PEC\", \"DTL_ATL\"]\n",
    "\n",
    "#cell_types = [\"PEC\", \"Immune\"]\n",
    "\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "metadata_path = metadat_path\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Read metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "unique_samples = metadata[metadata['Disease_level1'] != \"Control\"]['Sample'].unique()\n",
    "#sample_to_species = metadata.set_index('orig_ident')['species'].to_dict()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "#sample_counts_per_cell_type_per_species = {species: {ct: 0 for ct in cell_types} for species in metadata['species'].unique()}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    pval_df = pval_df[pval_df.index.isin(unique_samples)]\n",
    "    \n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "    #for sample in r2_df.index:\n",
    "        #species = sample_to_species.get(sample, \"Unknown\")\n",
    "        #sample_counts_per_cell_type_per_species[species][cell_type] += 1\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "\n",
    "    extracted_name = re.search(r'.*?_GO\\.\\d{7}\\.(.*?)\\.[A-Z]{2}$', label)\n",
    "    if extracted_name:\n",
    "        # Replace dots with spaces and split into words\n",
    "        words = extracted_name.group(1).replace('.', ' ').split()\n",
    "    else:\n",
    "        # If no match, return an empty string or some placeholder\n",
    "        return \"\"\n",
    "\n",
    "    # Start with the first word and check length as adding more words\n",
    "    split_label = words[0]\n",
    "    current_length = len(words[0])\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "\n",
    "# Provided cell types and colors\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#000004\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Function to extract cell type from feature name\n",
    "def extract_cell_type(feature_name):\n",
    "    for cell_type in cell_colors.keys():\n",
    "        if feature_name.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Sample data - replace with your actual data\n",
    "\n",
    "top_20_features = combined_pval.loc[sample_of_interest].nsmallest(10)\n",
    "neg_log_pvals = -np.log10(top_20_features)\n",
    "r2_values = combined_r2.loc[sample_of_interest][top_20_features.index]\n",
    "\n",
    "# Create a reversed red colormap for R2 values\n",
    "cmap = plt.cm.Reds_r  # '_r' suffix to reverse the colormap\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)  # Normalization fixed from 0 to 1\n",
    "\n",
    "# Assuming 'significant_counts_df' is your DataFrame and it has a 'GeneSet' and 'NormalizedPercentage' column\n",
    "scale_factor = 4\n",
    "base_size = 100\n",
    "#base_size = 20\n",
    "\n",
    "# Map features to their normalized percentage\n",
    "feature_to_percentage = dict(zip(significant_counts_df['GeneSet'], significant_counts_df['NormalizedPercentage']))\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(top_20_features.index, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "ax.set_title(f'Top Features for Sample {sample_of_interest}', fontsize=14)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left')\n",
    "ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    \n",
    "    # Draw the bar for significance\n",
    "    ax.plot([0, neg_log_pval], [i, i], color=bar_color, linewidth=3)\n",
    "\n",
    "\n",
    "# Process each feature name through auto_split_label and set as y-tick labels\n",
    "processed_labels = [auto_split_label(feat) for feat in top_20_features.index]\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(processed_labels, fontsize=12)\n",
    "\n",
    "#ax.set_yticklabels(top_20_features.index, fontsize=20)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your desired order of cell types\n",
    "desired_order = [\n",
    "     \n",
    "\"PT\", \n",
    "\"TAL\", \n",
    "\"DCT_CNT_CD\", \n",
    "\"IC\",    \n",
    "\"EC\",\n",
    "\"Stromal\",      \n",
    "\"Immune\",   \n",
    "\"DTL_ATL\",  \n",
    "\"PEC\",           \n",
    "\"Podo\",    \n",
    "\n",
    "    \n",
    "]  # Replace with actual cell types\n",
    "\n",
    "#top_20_features = combined_pval.loc[sample_of_interest].nsmallest(100)\n",
    "\n",
    "sample_features = combined_pval.loc[sample_of_interest]\n",
    "\n",
    "top_20_features = sample_features[sample_features < p_value_threshold]\n",
    "\n",
    "# Assume 'combined_pval' is a DataFrame you have that contains the p-values\n",
    "\n",
    "# Select the top 50 gene sets from the top features\n",
    "top_gene_sets = top_20_features.index\n",
    "\n",
    "# Group the top gene sets by cell type\n",
    "grouped_data = pd.Series(top_gene_sets).apply(extract_cell_type).value_counts()\n",
    "\n",
    "categories = list(grouped_data.index)\n",
    "\n",
    "# Initialize ordered values with zero for all categories\n",
    "ordered_values = [grouped_data.get(ct, 0) for ct in desired_order]\n",
    "\n",
    "# Since we need to repeat the first value to close the circular graph\n",
    "ordered_values += ordered_values[:1]\n",
    "\n",
    "# Calculate the angle of each axis in the plot\n",
    "N = len(desired_order)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize the spider plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], desired_order)\n",
    "\n",
    "# Draw ylabels and set plot limits\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(color=\"grey\", size=5)\n",
    "#plt.ylim(0, 1200)\n",
    "\n",
    "\n",
    "# Neutral color for shading\n",
    "shade_color = 'lightgrey'\n",
    "\n",
    "# Fill the entire area under the radar chart with a neutral color\n",
    "ax.fill(angles, ordered_values, shade_color, alpha=0.9)\n",
    "\n",
    "# Draw thin lines connecting the points\n",
    "ax.plot(angles, ordered_values, color='grey', linewidth=1, linestyle='-', alpha=0.8)\n",
    "\n",
    "# Plot each line segment in its respective cell type color\n",
    "for idx in range(N):\n",
    "    color = cell_colors.get(desired_order[idx], \"grey\")\n",
    "    ax.plot([angles[idx], 0], [ordered_values[idx], 0], color=color, linewidth=2)\n",
    "\n",
    "\n",
    "#########THIS WAS FIXED############\n",
    "# List to store cell types with all NaN values\n",
    "missing_samples = []\n",
    "\n",
    "# Loop through each cell type\n",
    "for celltype in desired_order:\n",
    "    # Subset 'allfeatures' to only include features starting with the current cell type\n",
    "    celltype_features = sample_features[sample_features.index.str.startswith(celltype)]\n",
    "    \n",
    "    # Check if the number of NaN values is above the threshold\n",
    "    if celltype_features.isna().sum() > nan_threshold:\n",
    "        # Add the celltype to the missing_samples list\n",
    "        missing_samples.append(celltype)\n",
    "\n",
    "for idx, label in enumerate(ax.get_xticklabels()):\n",
    "    # Check if the cell type is in the missing_samples list\n",
    "    if desired_order[idx] in missing_samples:\n",
    "        label.set_color('red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Cell Type Distribution in Top Gene Sets for Sample ' + sample_of_interest, size=11, y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot1\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(20)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefedfe-9352-43fc-a3af-dc8e01ff651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_of_interest = 'KRAD70'\n",
    "\n",
    "#max_value = 300\n",
    "\n",
    "ct_plot1 = \"DCT_CNT_CD\"\n",
    "\n",
    "ct_plot2 = \"PEC\"\n",
    "\n",
    "ct_plot3 = \"PT\"\n",
    "\n",
    "\n",
    "# Replace with your actual file paths and cell types\n",
    "cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"] # etc.\n",
    "# Paths as specified in your first script\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"  # or some default value\n",
    "\n",
    "# Read metadata\n",
    "metadat = pd.read_csv(metadat_path)\n",
    "unique_samples = metadat[metadat['Disease_level2'] != \"Control\"]['Sample'].unique()\n",
    "#unique_samples = metadat[(metadat['Disease_level2'] != \"Control\") & (metadat['Project/Dataset'] == \"cal_CKD\")]['Sample'].unique()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    \n",
    "    # Modify column names\n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    # Merge data\n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    # Count samples per cell type\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "\n",
    "# Handle NA values in p-values\n",
    "combined_pval.fillna(1, inplace=True)\n",
    "\n",
    "print(combined_r2)\n",
    "\n",
    "# Initialize a MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the combined_r2 data\n",
    "# Note: The fit_transform method expects a 2D array, so we use .values to convert the DataFrame\n",
    "min_max_scaled_r2_values = min_max_scaler.fit_transform(combined_r2.values)\n",
    "\n",
    "# Create a new DataFrame from the min-max scaled data, preserving the index and column names\n",
    "\n",
    "combined_r2 = pd.DataFrame(min_max_scaled_r2_values, index=combined_r2.index, columns=combined_r2.columns)\n",
    "\n",
    "# Set p-value threshold\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "# Identify significant gene sets\n",
    "significant_matrix = combined_pval < p_value_threshold\n",
    "\n",
    "# Count significant occurrences\n",
    "significant_counts = significant_matrix.sum()\n",
    "\n",
    "# Create DataFrame for counts and cell types\n",
    "significant_counts_df = pd.DataFrame({'GeneSet': significant_counts.index, 'Count': significant_counts.values})\n",
    "\n",
    "# Apply the function to extract the full cell type name\n",
    "significant_counts_df['CellType'] = significant_counts_df['GeneSet'].apply(extract_cell_type)\n",
    "\n",
    "# Normalize by sample number per cell type\n",
    "significant_counts_df['NormalizedPercentage'] = significant_counts_df.apply(\n",
    "    lambda row: (row['Count'] / sample_counts_per_cell_type.get(row['CellType'], 1)) * 100, axis=1\n",
    ")\n",
    "\n",
    "# Display final DataFrame\n",
    "print(significant_counts_df.head())  # You can modify this to display as needed\n",
    "\n",
    "sorted_df = significant_counts_df.sort_values(by='NormalizedPercentage', ascending=False)\n",
    "display(sorted_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "    # Split the label into words\n",
    "    words = label.split()\n",
    "\n",
    "    # Function to remove suffix\n",
    "    def remove_suffix(word):\n",
    "        return re.sub(r'\\(GO:\\d{7}\\)$', '', word)\n",
    "\n",
    "    # Start with the first word (with suffix removed)\n",
    "    first_word = remove_suffix(words[0])\n",
    "    split_label = first_word\n",
    "    current_length = len(first_word)\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        word = remove_suffix(word)\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "\n",
    "# Provided cell types and colors\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#000004\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Function to extract cell type from feature name\n",
    "def extract_cell_type(feature_name):\n",
    "    for cell_type in cell_colors.keys():\n",
    "        if feature_name.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Sample data - replace with your actual data\n",
    "\n",
    "top_20_features = combined_pval.loc[sample_of_interest].nsmallest(25)\n",
    "neg_log_pvals = -np.log10(top_20_features)\n",
    "r2_values = combined_r2.loc[sample_of_interest][top_20_features.index]\n",
    "\n",
    "# Create a reversed red colormap for R2 values\n",
    "cmap = plt.cm.Reds_r  # '_r' suffix to reverse the colormap\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)  # Normalization fixed from 0 to 1\n",
    "\n",
    "# Assuming 'significant_counts_df' is your DataFrame and it has a 'GeneSet' and 'NormalizedPercentage' column\n",
    "scale_factor = 4\n",
    "base_size = 100\n",
    "#base_size = 20\n",
    "\n",
    "# Map features to their normalized percentage\n",
    "feature_to_percentage = dict(zip(significant_counts_df['GeneSet'], significant_counts_df['NormalizedPercentage']))\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(top_20_features.index, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "ax.set_title(f'Top Features for Sample {sample_of_interest}', fontsize=14)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left')\n",
    "ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define your desired order of cell types\n",
    "desired_order = [\n",
    "     \n",
    "\"PT\", \n",
    "\"TAL\", \n",
    "\"DCT_CNT_CD\", \n",
    "\"IC\",    \n",
    "\"EC\",\n",
    "\"Stromal\",      \n",
    "\"Immune\",   \n",
    "\"DTL_ATL\",  \n",
    "\"PEC\",           \n",
    "\"Podo\",    \n",
    "\n",
    "    \n",
    "]  # Replace with actual cell types\n",
    "\n",
    "#top_20_features = combined_pval.loc[sample_of_interest].nsmallest(100)\n",
    "\n",
    "sample_features = combined_pval.loc[sample_of_interest]\n",
    "\n",
    "top_20_features = sample_features[sample_features < p_value_threshold]\n",
    "\n",
    "# Assume 'combined_pval' is a DataFrame you have that contains the p-values\n",
    "\n",
    "# Select the top 50 gene sets from the top features\n",
    "top_gene_sets = top_20_features.index\n",
    "\n",
    "# Group the top gene sets by cell type\n",
    "grouped_data = pd.Series(top_gene_sets).apply(extract_cell_type).value_counts()\n",
    "\n",
    "categories = list(grouped_data.index)\n",
    "\n",
    "# Initialize ordered values with zero for all categories\n",
    "ordered_values = [grouped_data.get(ct, 0) for ct in desired_order]\n",
    "\n",
    "# Since we need to repeat the first value to close the circular graph\n",
    "ordered_values += ordered_values[:1]\n",
    "\n",
    "# Calculate the angle of each axis in the plot\n",
    "N = len(desired_order)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize the spider plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], desired_order)\n",
    "\n",
    "# Draw ylabels and set plot limits\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(color=\"grey\", size=5)\n",
    "\n",
    "\n",
    "#plt.ylim(0, max_value)\n",
    "\n",
    "\n",
    "# Neutral color for shading\n",
    "shade_color = 'lightgrey'\n",
    "\n",
    "# Fill the entire area under the radar chart with a neutral color\n",
    "ax.fill(angles, ordered_values, shade_color, alpha=0.9)\n",
    "\n",
    "# Draw thin lines connecting the points\n",
    "ax.plot(angles, ordered_values, color='grey', linewidth=1, linestyle='-', alpha=0.8)\n",
    "\n",
    "# Plot each line segment in its respective cell type color\n",
    "for idx in range(N):\n",
    "    color = cell_colors.get(desired_order[idx], \"grey\")\n",
    "    ax.plot([angles[idx], 0], [ordered_values[idx], 0], color=color, linewidth=2)\n",
    "\n",
    "# Change the color of tick labels to red if the cell type is missing\n",
    "for idx, label in enumerate(ax.get_xticklabels()):\n",
    "    if desired_order[idx] not in categories:\n",
    "        label.set_color('red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Cell Type Distribution in Top Gene Sets for Sample ' + sample_of_interest, size=11, y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot1\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot2\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot3\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b4c91-a069-4f3a-99c1-ce4a69b9caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_threshold = 0.05\n",
    "\n",
    "sample_of_interest = \"PKD4_humphreys_ADPKD\"\n",
    "\n",
    "#max_value = 300\n",
    "\n",
    "ct_plot1 = \"PT\"\n",
    "\n",
    "#specify how many nan we tolerate (critical if applying gene filtering during spectra analysis)\n",
    "nan_threshold = 1000\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define cell types and file paths\n",
    "cell_types = [\"PT\", \"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"IC\", \"Immune\", \"PEC\", \"DTL_ATL\"]\n",
    "\n",
    "#cell_types = [\"PEC\", \"Immune\"]\n",
    "\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "metadata_path = metadat_path\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Read metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "unique_samples = metadata[metadata['Disease_level1'] != \"Control\"]['Sample'].unique()\n",
    "#sample_to_species = metadata.set_index('orig_ident')['species'].to_dict()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "#sample_counts_per_cell_type_per_species = {species: {ct: 0 for ct in cell_types} for species in metadata['species'].unique()}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    pval_df = pval_df[pval_df.index.isin(unique_samples)]\n",
    "    \n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "    #for sample in r2_df.index:\n",
    "        #species = sample_to_species.get(sample, \"Unknown\")\n",
    "        #sample_counts_per_cell_type_per_species[species][cell_type] += 1\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "\n",
    "    extracted_name = re.search(r'.*?_GO\\.\\d{7}\\.(.*?)\\.[A-Z]{2}$', label)\n",
    "    if extracted_name:\n",
    "        # Replace dots with spaces and split into words\n",
    "        words = extracted_name.group(1).replace('.', ' ').split()\n",
    "    else:\n",
    "        # If no match, return an empty string or some placeholder\n",
    "        return \"\"\n",
    "\n",
    "    # Start with the first word and check length as adding more words\n",
    "    split_label = words[0]\n",
    "    current_length = len(words[0])\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "\n",
    "# Provided cell types and colors\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#000004\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Function to extract cell type from feature name\n",
    "def extract_cell_type(feature_name):\n",
    "    for cell_type in cell_colors.keys():\n",
    "        if feature_name.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Sample data - replace with your actual data\n",
    "\n",
    "top_20_features = combined_pval.loc[sample_of_interest].nsmallest(10)\n",
    "neg_log_pvals = -np.log10(top_20_features)\n",
    "r2_values = combined_r2.loc[sample_of_interest][top_20_features.index]\n",
    "\n",
    "# Create a reversed red colormap for R2 values\n",
    "cmap = plt.cm.Reds_r  # '_r' suffix to reverse the colormap\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)  # Normalization fixed from 0 to 1\n",
    "\n",
    "# Assuming 'significant_counts_df' is your DataFrame and it has a 'GeneSet' and 'NormalizedPercentage' column\n",
    "scale_factor = 4\n",
    "base_size = 100\n",
    "#base_size = 20\n",
    "\n",
    "# Map features to their normalized percentage\n",
    "feature_to_percentage = dict(zip(significant_counts_df['GeneSet'], significant_counts_df['NormalizedPercentage']))\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(top_20_features.index, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "ax.set_title(f'Top Features for Sample {sample_of_interest}', fontsize=14)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left')\n",
    "ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    \n",
    "    # Draw the bar for significance\n",
    "    ax.plot([0, neg_log_pval], [i, i], color=bar_color, linewidth=3)\n",
    "\n",
    "\n",
    "# Process each feature name through auto_split_label and set as y-tick labels\n",
    "processed_labels = [auto_split_label(feat) for feat in top_20_features.index]\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(processed_labels, fontsize=12)\n",
    "\n",
    "#ax.set_yticklabels(top_20_features.index, fontsize=20)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your desired order of cell types\n",
    "desired_order = [\n",
    "     \n",
    "\"PT\", \n",
    "\"TAL\", \n",
    "\"DCT_CNT_CD\", \n",
    "\"IC\",    \n",
    "\"EC\",\n",
    "\"Stromal\",      \n",
    "\"Immune\",   \n",
    "\"DTL_ATL\",  \n",
    "\"PEC\",           \n",
    "\"Podo\",    \n",
    "\n",
    "    \n",
    "]  # Replace with actual cell types\n",
    "\n",
    "#top_20_features = combined_pval.loc[sample_of_interest].nsmallest(100)\n",
    "\n",
    "sample_features = combined_pval.loc[sample_of_interest]\n",
    "\n",
    "top_20_features = sample_features[sample_features < p_value_threshold]\n",
    "\n",
    "# Assume 'combined_pval' is a DataFrame you have that contains the p-values\n",
    "\n",
    "# Select the top 50 gene sets from the top features\n",
    "top_gene_sets = top_20_features.index\n",
    "\n",
    "# Group the top gene sets by cell type\n",
    "grouped_data = pd.Series(top_gene_sets).apply(extract_cell_type).value_counts()\n",
    "\n",
    "categories = list(grouped_data.index)\n",
    "\n",
    "# Initialize ordered values with zero for all categories\n",
    "ordered_values = [grouped_data.get(ct, 0) for ct in desired_order]\n",
    "\n",
    "# Since we need to repeat the first value to close the circular graph\n",
    "ordered_values += ordered_values[:1]\n",
    "\n",
    "# Calculate the angle of each axis in the plot\n",
    "N = len(desired_order)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize the spider plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], desired_order)\n",
    "\n",
    "# Draw ylabels and set plot limits\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(color=\"grey\", size=5)\n",
    "#plt.ylim(0, 1200)\n",
    "\n",
    "\n",
    "# Neutral color for shading\n",
    "shade_color = 'lightgrey'\n",
    "\n",
    "# Fill the entire area under the radar chart with a neutral color\n",
    "ax.fill(angles, ordered_values, shade_color, alpha=0.9)\n",
    "\n",
    "# Draw thin lines connecting the points\n",
    "ax.plot(angles, ordered_values, color='grey', linewidth=1, linestyle='-', alpha=0.8)\n",
    "\n",
    "# Plot each line segment in its respective cell type color\n",
    "for idx in range(N):\n",
    "    color = cell_colors.get(desired_order[idx], \"grey\")\n",
    "    ax.plot([angles[idx], 0], [ordered_values[idx], 0], color=color, linewidth=2)\n",
    "\n",
    "\n",
    "#########THIS WAS FIXED############\n",
    "# List to store cell types with all NaN values\n",
    "missing_samples = []\n",
    "\n",
    "# Loop through each cell type\n",
    "for celltype in desired_order:\n",
    "    # Subset 'allfeatures' to only include features starting with the current cell type\n",
    "    celltype_features = sample_features[sample_features.index.str.startswith(celltype)]\n",
    "    \n",
    "    # Check if the number of NaN values is above the threshold\n",
    "    if celltype_features.isna().sum() > nan_threshold:\n",
    "        # Add the celltype to the missing_samples list\n",
    "        missing_samples.append(celltype)\n",
    "\n",
    "for idx, label in enumerate(ax.get_xticklabels()):\n",
    "    # Check if the cell type is in the missing_samples list\n",
    "    if desired_order[idx] in missing_samples:\n",
    "        label.set_color('red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Cell Type Distribution in Top Gene Sets for Sample ' + sample_of_interest, size=11, y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot1\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(20)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a30666-1867-49d7-8763-c0e6eaf3f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_of_interest = 'PKD4_humphreys_ADPKD'\n",
    "\n",
    "#max_value = 300\n",
    "\n",
    "ct_plot1 = \"DCT_CNT_CD\"\n",
    "\n",
    "ct_plot2 = \"TAL\"\n",
    "\n",
    "ct_plot3 = \"PT\"\n",
    "\n",
    "\n",
    "# Replace with your actual file paths and cell types\n",
    "cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"] # etc.\n",
    "# Paths as specified in your first script\n",
    "base_path = \"/home/isilon/users/o_kloetzer/Atlas/Revision/human_extended/output_human_extended/\"\n",
    "r2_folder = \"R2_GO_unfiltered/\"\n",
    "pval_folder = \"Padj_GO_unfiltered/\"\n",
    "metadat_path = \"/home/isilon/users/o_kloetzer/Atlas/scSPECTRA/R2_pval/Atlas_Extended_II_Albuminuria_gpt.csv\"  # Update with the actual path to 'metadat'\n",
    "\n",
    "def extract_cell_type(gene_set):\n",
    "    for cell_type in cell_types:\n",
    "        if gene_set.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"  # or some default value\n",
    "\n",
    "# Read metadata\n",
    "metadat = pd.read_csv(metadat_path)\n",
    "unique_samples = metadat[metadat['Disease_level2'] != \"Control\"]['Sample'].unique()\n",
    "#unique_samples = metadat[(metadat['Disease_level2'] != \"Control\") & (metadat['Project/Dataset'] == \"cal_CKD\")]['Sample'].unique()\n",
    "\n",
    "# Initialize combined dataframes for R2 and p-values\n",
    "combined_r2 = pd.DataFrame(index=unique_samples)\n",
    "combined_pval = pd.DataFrame(index=unique_samples)\n",
    "sample_counts_per_cell_type = {}\n",
    "\n",
    "# Process each cell type\n",
    "for cell_type in cell_types:\n",
    "    r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "    pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "    \n",
    "    r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "    pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "    \n",
    "    # Modify column names\n",
    "    r2_df.columns = [f\"{cell_type}_{col}\" for col in r2_df.columns]\n",
    "    pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "    \n",
    "    # Merge data\n",
    "    combined_r2 = combined_r2.join(r2_df, how='left')\n",
    "    combined_pval = combined_pval.join(pval_df, how='left')\n",
    "\n",
    "    # Count samples per cell type\n",
    "    r2_df = r2_df[r2_df.index.isin(unique_samples)]\n",
    "    sample_counts_per_cell_type[cell_type] = r2_df.shape[0]\n",
    "\n",
    "# Handle NA values in p-values\n",
    "combined_pval.fillna(1, inplace=True)\n",
    "\n",
    "print(combined_r2)\n",
    "\n",
    "# Initialize a MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the combined_r2 data\n",
    "# Note: The fit_transform method expects a 2D array, so we use .values to convert the DataFrame\n",
    "min_max_scaled_r2_values = min_max_scaler.fit_transform(combined_r2.values)\n",
    "\n",
    "# Create a new DataFrame from the min-max scaled data, preserving the index and column names\n",
    "\n",
    "combined_r2 = pd.DataFrame(min_max_scaled_r2_values, index=combined_r2.index, columns=combined_r2.columns)\n",
    "\n",
    "# Set p-value threshold\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "# Identify significant gene sets\n",
    "significant_matrix = combined_pval < p_value_threshold\n",
    "\n",
    "# Count significant occurrences\n",
    "significant_counts = significant_matrix.sum()\n",
    "\n",
    "# Create DataFrame for counts and cell types\n",
    "significant_counts_df = pd.DataFrame({'GeneSet': significant_counts.index, 'Count': significant_counts.values})\n",
    "\n",
    "# Apply the function to extract the full cell type name\n",
    "significant_counts_df['CellType'] = significant_counts_df['GeneSet'].apply(extract_cell_type)\n",
    "\n",
    "# Normalize by sample number per cell type\n",
    "significant_counts_df['NormalizedPercentage'] = significant_counts_df.apply(\n",
    "    lambda row: (row['Count'] / sample_counts_per_cell_type.get(row['CellType'], 1)) * 100, axis=1\n",
    ")\n",
    "\n",
    "# Display final DataFrame\n",
    "print(significant_counts_df.head())  # You can modify this to display as needed\n",
    "\n",
    "sorted_df = significant_counts_df.sort_values(by='NormalizedPercentage', ascending=False)\n",
    "display(sorted_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def auto_split_label(label, max_length=40):\n",
    "    # Split the label into words\n",
    "    words = label.split()\n",
    "\n",
    "    # Function to remove suffix\n",
    "    def remove_suffix(word):\n",
    "        return re.sub(r'\\(GO:\\d{7}\\)$', '', word)\n",
    "\n",
    "    # Start with the first word (with suffix removed)\n",
    "    first_word = remove_suffix(words[0])\n",
    "    split_label = first_word\n",
    "    current_length = len(first_word)\n",
    "\n",
    "    # Add each word to the line until the max_length is reached, then start a new line\n",
    "    for word in words[1:]:\n",
    "        word = remove_suffix(word)\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            split_label += ' ' + word\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_label += '\\n' + word\n",
    "            current_length = len(word)\n",
    "\n",
    "    return split_label\n",
    "\n",
    "\n",
    "# Provided cell types and colors\n",
    "cell_colors = {\n",
    "    \"DCT_CNT_CD\": \"#3182bd\",\n",
    "    \"DTL_ATL\": \"#fdd0a2\",\n",
    "    \"EC\": \"seagreen\",\n",
    "    \"IC\": \"orange\",\n",
    "    \"Immune\": \"#c7e9c0\",\n",
    "    \"Podo\": \"#000004\",\n",
    "    \"Stromal\": \"limegreen\",\n",
    "    \"PEC\": \"#fde725\",\n",
    "    \"PT\": \"darkorchid\",\n",
    "    \"TAL\": \"lightcoral\",\n",
    "}\n",
    "\n",
    "# Function to extract cell type from feature name\n",
    "def extract_cell_type(feature_name):\n",
    "    for cell_type in cell_colors.keys():\n",
    "        if feature_name.startswith(cell_type):\n",
    "            return cell_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Sample data - replace with your actual data\n",
    "\n",
    "top_20_features = combined_pval.loc[sample_of_interest].nsmallest(25)\n",
    "neg_log_pvals = -np.log10(top_20_features)\n",
    "r2_values = combined_r2.loc[sample_of_interest][top_20_features.index]\n",
    "\n",
    "# Create a reversed red colormap for R2 values\n",
    "cmap = plt.cm.Reds_r  # '_r' suffix to reverse the colormap\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)  # Normalization fixed from 0 to 1\n",
    "\n",
    "# Assuming 'significant_counts_df' is your DataFrame and it has a 'GeneSet' and 'NormalizedPercentage' column\n",
    "scale_factor = 4\n",
    "base_size = 100\n",
    "#base_size = 20\n",
    "\n",
    "# Map features to their normalized percentage\n",
    "feature_to_percentage = dict(zip(significant_counts_df['GeneSet'], significant_counts_df['NormalizedPercentage']))\n",
    "\n",
    "# Create the dot plot\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(top_20_features.index)))\n",
    "ax.set_yticklabels(top_20_features.index, fontsize=10)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=12)\n",
    "ax.set_ylabel('Features', fontsize=12)\n",
    "ax.set_title(f'Top Features for Sample {sample_of_interest}', fontsize=14)\n",
    "\n",
    "# Invert y-axis to have the most significant features at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left')\n",
    "ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define your desired order of cell types\n",
    "desired_order = [\n",
    "     \n",
    "\"PT\", \n",
    "\"TAL\", \n",
    "\"DCT_CNT_CD\", \n",
    "\"IC\",    \n",
    "\"EC\",\n",
    "\"Stromal\",      \n",
    "\"Immune\",   \n",
    "\"DTL_ATL\",  \n",
    "\"PEC\",           \n",
    "\"Podo\",    \n",
    "\n",
    "    \n",
    "]  # Replace with actual cell types\n",
    "\n",
    "#top_20_features = combined_pval.loc[sample_of_interest].nsmallest(100)\n",
    "\n",
    "sample_features = combined_pval.loc[sample_of_interest]\n",
    "\n",
    "top_20_features = sample_features[sample_features < p_value_threshold]\n",
    "\n",
    "# Assume 'combined_pval' is a DataFrame you have that contains the p-values\n",
    "\n",
    "# Select the top 50 gene sets from the top features\n",
    "top_gene_sets = top_20_features.index\n",
    "\n",
    "# Group the top gene sets by cell type\n",
    "grouped_data = pd.Series(top_gene_sets).apply(extract_cell_type).value_counts()\n",
    "\n",
    "categories = list(grouped_data.index)\n",
    "\n",
    "# Initialize ordered values with zero for all categories\n",
    "ordered_values = [grouped_data.get(ct, 0) for ct in desired_order]\n",
    "\n",
    "# Since we need to repeat the first value to close the circular graph\n",
    "ordered_values += ordered_values[:1]\n",
    "\n",
    "# Calculate the angle of each axis in the plot\n",
    "N = len(desired_order)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize the spider plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], desired_order)\n",
    "\n",
    "# Draw ylabels and set plot limits\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(color=\"grey\", size=5)\n",
    "\n",
    "\n",
    "#plt.ylim(0, max_value)\n",
    "\n",
    "\n",
    "# Neutral color for shading\n",
    "shade_color = 'lightgrey'\n",
    "\n",
    "# Fill the entire area under the radar chart with a neutral color\n",
    "ax.fill(angles, ordered_values, shade_color, alpha=0.9)\n",
    "\n",
    "# Draw thin lines connecting the points\n",
    "ax.plot(angles, ordered_values, color='grey', linewidth=1, linestyle='-', alpha=0.8)\n",
    "\n",
    "# Plot each line segment in its respective cell type color\n",
    "for idx in range(N):\n",
    "    color = cell_colors.get(desired_order[idx], \"grey\")\n",
    "    ax.plot([angles[idx], 0], [ordered_values[idx], 0], color=color, linewidth=2)\n",
    "\n",
    "# Change the color of tick labels to red if the cell type is missing\n",
    "for idx, label in enumerate(ax.get_xticklabels()):\n",
    "    if desired_order[idx] not in categories:\n",
    "        label.set_color('red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Cell Type Distribution in Top Gene Sets for Sample ' + sample_of_interest, size=11, y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot1\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot2\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Desired cell type for visualization\n",
    "desired_cell_type = ct_plot3\n",
    "\n",
    "# Assuming 'combined_pval' and 'combined_r2' are DataFrames with samples as rows and features as columns\n",
    "# Filter for the specific sample of interest\n",
    "sample_pvals = combined_pval.loc[sample_of_interest]\n",
    "sample_r2 = combined_r2.loc[sample_of_interest]\n",
    "\n",
    "# Filter the top features for the specific sample and cell type\n",
    "#top_features_for_sample = sample_pvals.nsmallest(25)\n",
    "filtered_features = sample_pvals[sample_pvals.index.map(extract_cell_type) == desired_cell_type].nsmallest(5)\n",
    "filtered_neg_log_pvals = -np.log10(filtered_features)\n",
    "filtered_r2_values = sample_r2[filtered_features.index]\n",
    "\n",
    "# Now, update the dot plot code to use the filtered data\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "for i, (feature, neg_log_pval) in enumerate(filtered_neg_log_pvals.items()):\n",
    "    cell_type = extract_cell_type(feature)\n",
    "    bar_color = cell_colors.get(cell_type, 'grey')\n",
    "    dot_color = cmap(norm(filtered_r2_values[feature]))\n",
    "    \n",
    "    # Get the normalized percentage for the dot size (if applicable)\n",
    "    normalized_percentage = feature_to_percentage.get(feature, 0)\n",
    "    dot_size = normalized_percentage * scale_factor + base_size\n",
    "\n",
    "    ax.plot([0, neg_log_pval - (neg_log_pval / 10)], [i, i], color=bar_color, linewidth=3)\n",
    "    ax.scatter(neg_log_pval, i, s=dot_size, color=dot_color, edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(filtered_features.index)))\n",
    "\n",
    "prefix_to_remove = f\"{desired_cell_type}_\"\n",
    "cleaned_labels = [label.replace(prefix_to_remove, '', 1) for label in filtered_features.index]\n",
    "\n",
    "# Apply the auto-splitting to each label\n",
    "cleaned_labels = [auto_split_label(label) for label in cleaned_labels]\n",
    "\n",
    "ax.set_yticklabels(cleaned_labels, fontsize=22)\n",
    "ax.set_xlabel('-log10(p-value)', fontsize=15)\n",
    "#ax.set_ylabel('Features', fontsize=12)\n",
    "#ax.set_title(f'Top Features for Sample {sample_of_interest} - Cell Type: {desired_cell_type}', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create a colorbar for the R2 values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, label='Scaled R2 Values', orientation='vertical')\n",
    "\n",
    "# Legend for cell types\n",
    "#cell_legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=cell_type) for cell_type, color in cell_colors.items()]\n",
    "#legend1 = ax.legend(handles=cell_legend_elements, title='Cell Types', bbox_to_anchor=(1.5, 1), loc='upper left')\n",
    "\n",
    "# Example normalized percentages for the dot size legend\n",
    "example_percentages = [20, 40, 60, 80]\n",
    "legend_dot_sizes = [p * scale_factor + base_size for p in example_percentages]\n",
    "\n",
    "# Add legend for dot sizes\n",
    "for p, size in zip(example_percentages, legend_dot_sizes):\n",
    "    ax.scatter([], [], s=size, color='gray', edgecolor='black', alpha=0.7, label=f'{p}%')\n",
    "\n",
    "legend2 = ax.legend(title='Frequency', bbox_to_anchor=(1.5, 0.2), loc='center left', fontsize='large')\n",
    "#ax.add_artist(legend1)  # Add back the first legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f85c84-0a6a-4aeb-a24b-103a1dee9265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20702f1-a7bf-4253-87ac-a198ddd7a39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784656ac-392a-4ccd-a569-ebec32f8a1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1dcb5f-d94a-40d2-b34c-9d1306607c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "nan_threshold = 1000\n",
    "\n",
    "metadat = metadata\n",
    "\n",
    "# Define the cell types and the base paths\n",
    "#cell_types = [\"Cancer\", \"Stromal\", \"Endothelial\"]\n",
    "#cell_types = [\"Podo\", \"TAL\", \"DCT_CNT_CD\", \"EC\", \"Stromal\", \"Immune\", \"PEC\", \"PT\", \"IC\", \"DTL_ATL\"]  # etc.\n",
    "cell_types = [\"TAL\"]  # etc.\n",
    "\n",
    "\n",
    "# Function to read and process data for samples based on GFR threshold\n",
    "def process_condition(metadat, unique_samples):\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    combined_pval = pd.DataFrame(index=unique_samples)\n",
    "    for cell_type in cell_types:\n",
    "        pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "        pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "        pval_df = pval_df[pval_df.index.isin(unique_samples)]\n",
    "        pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "        combined_pval = combined_pval.join(pval_df, how='left')\n",
    "    return combined_pval\n",
    "\n",
    "# Function to count significance\n",
    "def count_significance(pval_df, threshold=0.05):\n",
    "    sig_count = (pval_df < threshold).sum(axis=0, skipna=True)\n",
    "    nonsig_count = (pval_df >= threshold).sum(axis=0, skipna=True)\n",
    "    return sig_count, nonsig_count\n",
    "\n",
    "# Read metadata\n",
    "\n",
    "#metadata[(metadata['tissue: tumor_primary'] == 1.0) & (metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUSC\")]['patient'].unique()\n",
    "\n",
    "# Process each condition based on GFR threshold\n",
    "#combined_pval_cond1 = process_condition(metadata, metadata[(metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUAD\")][\"patient\"].tolist())  # Samples above the threshold\n",
    "#combined_pval_cond2 = process_condition(metadata, metadata[(metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUSC\")][\"patient\"].tolist())  # Samples below the threshold\n",
    "\n",
    "combined_pval_cond1 = process_condition(metadata, metadata[(metadata['Disease_level1'] != \"Control\") & (metadata['Sex'] == \"male\")][\"Sample\"].tolist())  # Samples above the threshold\n",
    "combined_pval_cond2 = process_condition(metadata, metadata[(metadata['Disease_level1'] != \"Control\") & (metadata['Sex'] == \"female\")][\"Sample\"].tolist())  # Samples below the threshold\n",
    "\n",
    "\n",
    "#filter out the samples with too many nan\n",
    "# Count the number of NaN values per sample (row) in the combined_pval DataFrame\n",
    "nan_counts_per_sample1 = combined_pval_cond1.isna().sum(axis=1)\n",
    "nan_counts_per_sample2 = combined_pval_cond2.isna().sum(axis=1)\n",
    "\n",
    "# Exclude samples with more than the defined threshold of NaNs\n",
    "samples_to_exclude1 = nan_counts_per_sample1[nan_counts_per_sample1 > nan_threshold].index\n",
    "samples_to_exclude2 = nan_counts_per_sample2[nan_counts_per_sample2 > nan_threshold].index\n",
    "\n",
    "combined_pval_cond1 = combined_pval_cond1.drop(samples_to_exclude1, axis=0)\n",
    "combined_pval_cond2 = combined_pval_cond2.drop(samples_to_exclude2, axis=0)\n",
    "\n",
    "\n",
    "# Count significance for each condition\n",
    "sig_count_cond1, nonsig_count_cond1 = count_significance(combined_pval_cond1)\n",
    "sig_count_cond2, nonsig_count_cond2 = count_significance(combined_pval_cond2)\n",
    "\n",
    "# Creating the comparison DataFrame\n",
    "comparison_df = pd.DataFrame(columns=combined_pval_cond1.columns, index=['cond1_sig', 'cond1_nonsig', 'cond2_sig', 'cond2_nonsig'])\n",
    "comparison_df.loc['cond1_sig'] = sig_count_cond1\n",
    "comparison_df.loc['cond1_nonsig'] = nonsig_count_cond1\n",
    "comparison_df.loc['cond2_sig'] = sig_count_cond2\n",
    "comparison_df.loc['cond2_nonsig'] = nonsig_count_cond2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Assuming the comparison_df has been generated as in the previous code\n",
    "\n",
    "fisher_results = pd.DataFrame(columns=['Feature', 'Test_statistic', 'p_value', \"odds_ratio\", 'cond1_sig_count', 'cond2_sig_count'])\n",
    "\n",
    "for feature in comparison_df.columns:\n",
    "    # Creating the contingency table for each feature\n",
    "    contingency_table = comparison_df[[feature]].values.reshape(2, 2)\n",
    "    \n",
    "    # Extract counts of significant samples for each condition for the current feature\n",
    "    cond1_sig_count = comparison_df.loc['cond1_sig', feature]\n",
    "    cond2_sig_count = comparison_df.loc['cond2_sig', feature]\n",
    "\n",
    "    # Apply Fisher's Exact Test\n",
    "    odds_ratio, p = fisher_exact(contingency_table)\n",
    "    \n",
    "    # Store the results\n",
    "    result_row = pd.DataFrame([{\n",
    "        'Feature': feature, \n",
    "        'Test_statistic': odds_ratio, \n",
    "        'p_value': p, \n",
    "        \"odds_ratio\": odds_ratio, \n",
    "        'cond1_sig_count': cond1_sig_count,\n",
    "        'cond2_sig_count': cond2_sig_count\n",
    "    }])\n",
    "    \n",
    "    fisher_results = pd.concat([fisher_results, result_row], ignore_index=True)\n",
    "\n",
    "# Sort the results by p-value in ascending order\n",
    "sorted_results = fisher_results.sort_values(by='p_value')\n",
    "\n",
    "# Display the most significant features\n",
    "print(sorted_results.head())  # Adjust the number inside head() as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa344ca-e1c0-4305-a8fb-2516ae598418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "# Extract the original p-values\n",
    "p_values = sorted_results['p_value'].values\n",
    "\n",
    "# Apply multiple test correction (using Benjamini-Hochberg method as an example)\n",
    "correction_method = 'fdr_bh'  # You can change this to 'bonferroni', 'holm', etc., based on your requirement\n",
    "rejected, corrected_p_values, _, _ = multipletests(p_values, alpha=0.05, method=correction_method)\n",
    "\n",
    "# Add the corrected p-values to your DataFrame\n",
    "sorted_results['corrected_p_value'] = corrected_p_values\n",
    "sorted_results['rejected_h0'] = rejected\n",
    "\n",
    "# Now sorted_results has an additional column with corrected p-values\n",
    "print(sorted_results.head())  # Adjust the number inside head() as needed\n",
    "\n",
    "sorted_results.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ece9d6-0f1f-430e-bb2a-2e83d58becc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Define the path to the R2 file for the specific cell type and gene set\n",
    "#r2_base_path = \"/home/kloetzer/Atlas/scSpectra/species_healthy_disease/\"\n",
    "cell_type = \"TAL\"  # Replace with your desired cell type\n",
    "target_gene_set = \"Postsynaptic Membrane Organization (GO:0001941)\"  # Replace with your desired gene set name\n",
    "\n",
    "metadata = metadat\n",
    "\n",
    "# Load the R2 file\n",
    "r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "\n",
    "r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "\n",
    "# Define the sample groups (time points)\n",
    "\n",
    "#group0 = metadata[(metadata[\"proj\"]==\"m_humphreys_DKD\") & (metadata[\"treated\"]==\"Control_diseased\")].orig_ident.unique().tolist()\n",
    "#group0 = metadata[(metadata['Hypertension']==\"Yes\")].Sample.unique().tolist()\n",
    "\n",
    "#group1 = metadata[(metadata[\"proj\"]==\"m_humphreys_DKD\") & (metadata[\"treated\"]==\"SLGT2i\")].orig_ident.unique().tolist()\n",
    "group1 = metadata[(metadata['Sex']==\"female\") & (metadata['Disease_level1']!=\"Control\")].Sample.unique().tolist()\n",
    "\n",
    "group2 = metadata[(metadata['Sex']==\"male\") & (metadata['Disease_level1']!=\"Control\")].Sample.unique().tolist()\n",
    "\n",
    "\n",
    "samples_to_remove = []\n",
    "samples_to_remove = ['34-10240', 'HK2886']\n",
    "\n",
    "# Creating the list with samples to be removed\n",
    "#group0 = [sample for sample in group0 if sample not in samples_to_remove]\n",
    "\n",
    "group1 = [sample for sample in group1 if sample not in samples_to_remove]\n",
    "\n",
    "group2 = [sample for sample in group2 if sample not in samples_to_remove]\n",
    "\n",
    "# Identify significant samples based on Pval < 0.05 for the specific gene set\n",
    "significant_samples = pval_df.index[pval_df[target_gene_set] < 0.05]\n",
    "\n",
    "\n",
    "# Assuming the rest of your setup code (loading data, etc.) is here\n",
    "\n",
    "# Define x-coordinates for the groups, closer together\n",
    "group_positions = [0.5, 0.7]  # Adjust these values as needed\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(2.5, 6))\n",
    "\n",
    "# Initialize lists to store mean R2 values for each group\n",
    "mean_r2_values = []\n",
    "\n",
    "# Plot each individual sample at the new group positions\n",
    "for i, group in enumerate([group1, group2]):\n",
    "    group_r2_values = r2_df.loc[group, target_gene_set]\n",
    "    mean_r2 = group_r2_values.mean()\n",
    "    mean_r2_values.append(mean_r2)\n",
    "\n",
    "    for sample in group:\n",
    "        x_position = group_positions[i]  # x-coordinate for this group\n",
    "        color = 'red' if sample in significant_samples else 'blue'\n",
    "        plt.plot(x_position, group_r2_values.loc[sample], marker='o', markersize=5, color=color)\n",
    "\n",
    "# Plot the mean R2 values\n",
    "plt.plot(group_positions, mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2')\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylim(0.0, 1)  # Set the y-axis range from 0 to 1\n",
    "plt.xlim(0.3, 0.9)  # Set the x-axis range\n",
    "plt.xlabel(cell_type)\n",
    "plt.ylabel(\"R2 Value\")\n",
    "plt.title(target_gene_set)\n",
    "plt.xticks(group_positions, [\"female\", \"male\"])  # Set custom x-axis ticks\n",
    "#plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = pd.DataFrame()\n",
    "for i, group in enumerate([group1, group2]):\n",
    "    group_r2_values = r2_df.loc[group, target_gene_set]\n",
    "    group_data = pd.DataFrame({'R2 Value': group_r2_values, 'Group': i, 'Sample': group_r2_values.index})\n",
    "    plot_data = pd.concat([plot_data, group_data])\n",
    "\n",
    "# Add a column for color based on significance\n",
    "plot_data['Color'] = plot_data['Sample'].apply(lambda x: 'red' if x in significant_samples else 'blue')\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(2, 6))\n",
    "\n",
    "# Create a beeswarm plot\n",
    "\n",
    "sns.swarmplot(x='Group', y='R2 Value', data=plot_data, hue='Color', palette=['blue', 'red'])\n",
    "plt.plot(mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2', zorder=10, markersize=12,\n",
    "        markeredgewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylim(0.5, 1)  # Set the y-axis range from 0 to 1\n",
    "plt.xlabel(cell_type)\n",
    "plt.ylabel(\"R2 Value\")\n",
    "plt.title(target_gene_set)\n",
    "plt.xticks([0, 1], [\"female\", \"male\"])  # Set custom x-axis ticks\n",
    "plt.legend().remove()  # Remove the legend if not needed\n",
    "plt.grid(False)\n",
    "plt.plot(mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3b69e-9392-4bea-befd-2bdf2e416b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "nan_threshold = 1000\n",
    "\n",
    "metadat = metadata\n",
    "\n",
    "# Define the cell types and the base paths\n",
    "#cell_types = [\"Cancer\", \"Stromal\", \"Endothelial\"]\n",
    "cell_types = [\"DCT_CNT_CD\"]\n",
    "\n",
    "\n",
    "# Function to read and process data for samples based on GFR threshold\n",
    "def process_condition(metadat, unique_samples):\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    combined_pval = pd.DataFrame(index=unique_samples)\n",
    "    for cell_type in cell_types:\n",
    "        pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "        pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "        pval_df = pval_df[pval_df.index.isin(unique_samples)]\n",
    "        pval_df.columns = [f\"{cell_type}_{col}\" for col in pval_df.columns]\n",
    "        combined_pval = combined_pval.join(pval_df, how='left')\n",
    "    return combined_pval\n",
    "\n",
    "# Function to count significance\n",
    "def count_significance(pval_df, threshold=0.05):\n",
    "    sig_count = (pval_df < threshold).sum(axis=0, skipna=True)\n",
    "    nonsig_count = (pval_df >= threshold).sum(axis=0, skipna=True)\n",
    "    return sig_count, nonsig_count\n",
    "\n",
    "# Read metadata\n",
    "\n",
    "#metadata[(metadata['tissue: tumor_primary'] == 1.0) & (metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUSC\")]['patient'].unique()\n",
    "\n",
    "# Process each condition based on GFR threshold\n",
    "#combined_pval_cond1 = process_condition(metadata, metadata[(metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUAD\")][\"patient\"].tolist())  # Samples above the threshold\n",
    "#combined_pval_cond2 = process_condition(metadata, metadata[(metadata['platform'] == \"10x\") & (metadata['condition'] == \"LUSC\")][\"patient\"].tolist())  # Samples below the threshold\n",
    "\n",
    "combined_pval_cond1 = process_condition(metadata, metadata[(metadata['Disease_level1'] != \"Control\") & (metadata['Hypertension'] == \"No\")][\"Sample\"].tolist())  # Samples above the threshold\n",
    "combined_pval_cond2 = process_condition(metadata, metadata[(metadata['Disease_level1'] != \"Control\") & (metadata['Hypertension'] == \"Yes\")][\"Sample\"].tolist())  # Samples below the threshold\n",
    "\n",
    "\n",
    "#filter out the samples with too many nan\n",
    "# Count the number of NaN values per sample (row) in the combined_pval DataFrame\n",
    "nan_counts_per_sample1 = combined_pval_cond1.isna().sum(axis=1)\n",
    "nan_counts_per_sample2 = combined_pval_cond2.isna().sum(axis=1)\n",
    "\n",
    "# Exclude samples with more than the defined threshold of NaNs\n",
    "samples_to_exclude1 = nan_counts_per_sample1[nan_counts_per_sample1 > nan_threshold].index\n",
    "samples_to_exclude2 = nan_counts_per_sample2[nan_counts_per_sample2 > nan_threshold].index\n",
    "\n",
    "combined_pval_cond1 = combined_pval_cond1.drop(samples_to_exclude1, axis=0)\n",
    "combined_pval_cond2 = combined_pval_cond2.drop(samples_to_exclude2, axis=0)\n",
    "\n",
    "\n",
    "# Count significance for each condition\n",
    "sig_count_cond1, nonsig_count_cond1 = count_significance(combined_pval_cond1)\n",
    "sig_count_cond2, nonsig_count_cond2 = count_significance(combined_pval_cond2)\n",
    "\n",
    "# Creating the comparison DataFrame\n",
    "comparison_df = pd.DataFrame(columns=combined_pval_cond1.columns, index=['cond1_sig', 'cond1_nonsig', 'cond2_sig', 'cond2_nonsig'])\n",
    "comparison_df.loc['cond1_sig'] = sig_count_cond1\n",
    "comparison_df.loc['cond1_nonsig'] = nonsig_count_cond1\n",
    "comparison_df.loc['cond2_sig'] = sig_count_cond2\n",
    "comparison_df.loc['cond2_nonsig'] = nonsig_count_cond2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Assuming the comparison_df has been generated as in the previous code\n",
    "\n",
    "fisher_results = pd.DataFrame(columns=['Feature', 'Test_statistic', 'p_value', \"odds_ratio\", 'cond1_sig_count', 'cond2_sig_count'])\n",
    "\n",
    "for feature in comparison_df.columns:\n",
    "    # Creating the contingency table for each feature\n",
    "    contingency_table = comparison_df[[feature]].values.reshape(2, 2)\n",
    "    \n",
    "    # Extract counts of significant samples for each condition for the current feature\n",
    "    cond1_sig_count = comparison_df.loc['cond1_sig', feature]\n",
    "    cond2_sig_count = comparison_df.loc['cond2_sig', feature]\n",
    "\n",
    "    # Apply Fisher's Exact Test\n",
    "    odds_ratio, p = fisher_exact(contingency_table)\n",
    "    \n",
    "    # Store the results\n",
    "    result_row = pd.DataFrame([{\n",
    "        'Feature': feature, \n",
    "        'Test_statistic': odds_ratio, \n",
    "        'p_value': p, \n",
    "        \"odds_ratio\": odds_ratio, \n",
    "        'cond1_sig_count': cond1_sig_count,\n",
    "        'cond2_sig_count': cond2_sig_count\n",
    "    }])\n",
    "    \n",
    "    fisher_results = pd.concat([fisher_results, result_row], ignore_index=True)\n",
    "\n",
    "# Sort the results by p-value in ascending order\n",
    "sorted_results = fisher_results.sort_values(by='p_value')\n",
    "\n",
    "# Display the most significant features\n",
    "print(sorted_results.head())  # Adjust the number inside head() as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69415be8-b045-4454-a95d-e73b5475c252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cc715-c09a-425f-9041-86329749c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "# Extract the original p-values\n",
    "p_values = sorted_results['p_value'].values\n",
    "\n",
    "# Apply multiple test correction (using Benjamini-Hochberg method as an example)\n",
    "correction_method = 'fdr_bh'  # You can change this to 'bonferroni', 'holm', etc., based on your requirement\n",
    "rejected, corrected_p_values, _, _ = multipletests(p_values, alpha=0.05, method=correction_method)\n",
    "\n",
    "# Add the corrected p-values to your DataFrame\n",
    "sorted_results['corrected_p_value'] = corrected_p_values\n",
    "sorted_results['rejected_h0'] = rejected\n",
    "\n",
    "# Now sorted_results has an additional column with corrected p-values\n",
    "print(sorted_results.head())  # Adjust the number inside head() as needed\n",
    "\n",
    "sorted_results.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e52196-def0-4010-b8d8-9abc1ffb1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Define the path to the R2 file for the specific cell type and gene set\n",
    "#r2_base_path = \"/home/kloetzer/Atlas/scSpectra/species_healthy_disease/\"\n",
    "cell_type = \"DCT_CNT_CD\"  # Replace with your desired cell type\n",
    "target_gene_set = \"Regulation Of Monoatomic Ion Transmembrane Transport (GO:0034765)\"  # Replace with your desired gene set name\n",
    "\n",
    "metadata = metadat\n",
    "\n",
    "# Load the R2 file\n",
    "r2_path = os.path.join(base_path, r2_folder, f\"R2_{cell_type}.csv\")\n",
    "pval_path = os.path.join(base_path, pval_folder, f\"Pval_{cell_type}.csv\")\n",
    "\n",
    "r2_df = pd.read_csv(r2_path, index_col=0)\n",
    "pval_df = pd.read_csv(pval_path, index_col=0)\n",
    "\n",
    "# Define the sample groups (time points)\n",
    "\n",
    "#group0 = metadata[(metadata[\"proj\"]==\"m_humphreys_DKD\") & (metadata[\"treated\"]==\"Control_diseased\")].orig_ident.unique().tolist()\n",
    "#group0 = metadata[(metadata['Hypertension']==\"Yes\")].Sample.unique().tolist()\n",
    "\n",
    "#group1 = metadata[(metadata[\"proj\"]==\"m_humphreys_DKD\") & (metadata[\"treated\"]==\"SLGT2i\")].orig_ident.unique().tolist()\n",
    "group1 = metadata[(metadata['Hypertension']==\"No\") & (metadata['Disease_level1']!=\"Control\")].Sample.unique().tolist()\n",
    "\n",
    "group2 = metadata[(metadata['Hypertension']==\"Yes\") & (metadata['Disease_level1']!=\"Control\")].Sample.unique().tolist()\n",
    "\n",
    "\n",
    "samples_to_remove = []\n",
    "samples_to_remove = ['HK2886', '32-10346']\n",
    "\n",
    "# Creating the list with samples to be removed\n",
    "#group0 = [sample for sample in group0 if sample not in samples_to_remove]\n",
    "\n",
    "group1 = [sample for sample in group1 if sample not in samples_to_remove]\n",
    "\n",
    "group2 = [sample for sample in group2 if sample not in samples_to_remove]\n",
    "\n",
    "# Identify significant samples based on Pval < 0.05 for the specific gene set\n",
    "significant_samples = pval_df.index[pval_df[target_gene_set] < 0.05]\n",
    "\n",
    "\n",
    "# Assuming the rest of your setup code (loading data, etc.) is here\n",
    "\n",
    "# Define x-coordinates for the groups, closer together\n",
    "group_positions = [0.5, 0.7]  # Adjust these values as needed\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(2.5, 6))\n",
    "\n",
    "# Initialize lists to store mean R2 values for each group\n",
    "mean_r2_values = []\n",
    "\n",
    "# Plot each individual sample at the new group positions\n",
    "for i, group in enumerate([group1, group2]):\n",
    "    group_r2_values = r2_df.loc[group, target_gene_set]\n",
    "    mean_r2 = group_r2_values.mean()\n",
    "    mean_r2_values.append(mean_r2)\n",
    "\n",
    "    for sample in group:\n",
    "        x_position = group_positions[i]  # x-coordinate for this group\n",
    "        color = 'red' if sample in significant_samples else 'blue'\n",
    "        plt.plot(x_position, group_r2_values.loc[sample], marker='o', markersize=5, color=color)\n",
    "\n",
    "# Plot the mean R2 values\n",
    "plt.plot(group_positions, mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2')\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylim(0.5, 1)  # Set the y-axis range from 0 to 1\n",
    "plt.xlim(0.3, 0.9)  # Set the x-axis range\n",
    "plt.xlabel(cell_type)\n",
    "plt.ylabel(\"R2 Value\")\n",
    "plt.title(target_gene_set)\n",
    "plt.xticks(group_positions, [\"No\", \"Yes\"])  # Set custom x-axis ticks\n",
    "#plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = pd.DataFrame()\n",
    "for i, group in enumerate([group1, group2]):\n",
    "    group_r2_values = r2_df.loc[group, target_gene_set]\n",
    "    group_data = pd.DataFrame({'R2 Value': group_r2_values, 'Group': i, 'Sample': group_r2_values.index})\n",
    "    plot_data = pd.concat([plot_data, group_data])\n",
    "\n",
    "# Add a column for color based on significance\n",
    "plot_data['Color'] = plot_data['Sample'].apply(lambda x: 'red' if x in significant_samples else 'blue')\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(2, 6))\n",
    "\n",
    "# Create a beeswarm plot\n",
    "\n",
    "sns.swarmplot(x='Group', y='R2 Value', data=plot_data, hue='Color', palette=['blue', 'red'])\n",
    "plt.plot(mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2', zorder=10, markersize=12,\n",
    "        markeredgewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylim(0.5, 1)  # Set the y-axis range from 0 to 1\n",
    "plt.xlabel(cell_type)\n",
    "plt.ylabel(\"R2 Value\")\n",
    "plt.title(target_gene_set)\n",
    "plt.xticks([0, 1], [\"No\", \"Yes\"])  # Set custom x-axis ticks\n",
    "plt.legend().remove()  # Remove the legend if not needed\n",
    "plt.grid(False)\n",
    "plt.plot(mean_r2_values, marker='_', color='black', linestyle='', label='Mean R2')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-pip",
   "language": "python",
   "name": "scvi-pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
